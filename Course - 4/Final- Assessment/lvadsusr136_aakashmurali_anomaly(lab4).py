# -*- coding: utf-8 -*-
"""lvadsusr136_aakashmurali_anomaly(lab4).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L7fDsKz5xoELU5DGnDwrneLFn_Cgg37m
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time
from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support
from sklearn.metrics import precision_recall_curve,confusion_matrix, ConfusionMatrixDisplay
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier , RandomForestRegressor
from sklearn.ensemble import IsolationForest
import collections
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.metrics import classification_report_imbalanced
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report,silhouette_score
from sklearn.model_selection import KFold, StratifiedKFold
import random
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler , LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support, precision_recall_curve
import warnings
warnings.filterwarnings("ignore")

df=pd.read_csv('https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch5-Assessment/main/anomaly_train.csv')
df.head()

#understanding the data
df.shape
df.info()

#checking for null values , there aren't any
df.isnull().sum()

#checking for duplicate values
df.duplicated().sum()

#encodind the features
encode=LabelEncoder()
for col in df.select_dtypes(include='object').columns:
  df[col]=encode.fit_transform(df[col])
df.head()
#scaling the data
'''scale=MinMaxScaler()
for col in df.columns:
  df[col]=scale.fit_transform(df[[col]])
df.head(0)'''

#training the model with the Isolation forest algorithm
model=IsolationForest()
model.fit(df)
pred=model.predict(df)

#Adding features in data
df['Anomaly_score']=model.decision_function(df)
df['Anomaly']=pred
df.head()

df['Anomaly']=df['Anomaly'].map({-1:'Yes',0:'No',1:'No'})

anomalies=df[df['Anomaly']=='Yes']
df=df[df['Anomaly']!='Yes']

anomalies.head()

#plotting for the better understanding of the anomalies
plt.scatter(df['TransactionID'],df['Anomaly_score'],c='blue')
plt.scatter(anomalies['TransactionID'],anomalies['Anomaly_score'],c='yellow')
plt.legend(['Normal','Anomaly'])
plt.show()