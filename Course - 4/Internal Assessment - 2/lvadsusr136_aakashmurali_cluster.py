# -*- coding: utf-8 -*-
"""lvadsusr136_aakashmurali_cluster.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10pl8ppSBk_YGCdAkz0rerk7RyhZkj32n
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time
from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support
from sklearn.metrics import precision_recall_curve,confusion_matrix, ConfusionMatrixDisplay
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import collections
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.metrics import classification_report_imbalanced
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report,silhouette_score
from sklearn.model_selection import KFold, StratifiedKFold
import random
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler , LabelEncoder , StandardScaler
from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support, precision_recall_curve
import warnings
warnings.filterwarnings("ignore")

df=pd.read_csv('https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch5-Assessment/main/Mall_Customers.csv')
df.head()

df.info()

df.shape

'''df.dropna(inplace=True)'''

df.isnull().sum() # Column - Annual Income has 10 null values
df['Annual Income (k$)']=df['Annual Income (k$)'].fillna(df['Annual Income (k$)'].mean())

df['Gender']=df['Gender'].map({"Male":1,"Female":0})
df.head()

df['earn_to_spend']=df['Annual Income (k$)']/df['Spending Score (1-100)']
df.head()

'''df['Annual Income (k$)']=df['Annual Income (k$)']*1000
df.head()'''

corr=df.corr()
sns.heatmap(corr,annot=True)
plt.show()

'''df.drop('CustomerID',axis=1,inplace=True)
df.head()'''

#without scaling , the silhoutte score is 0.48

encoding=StandardScaler()
df['Spending Score (1-100)']=encoding.fit_transform(df[['Spending Score (1-100)']])
df['Annual Income (k$)']=encoding.fit_transform(df[['Annual Income (k$)']])
df.head()

'''encoding=MinMaxScaler()
for col in df.select_dtypes(include='float').columns:
  df[col]=encoding.fit_transform(df[[col]])
df.head('''

corr=df.corr()
sns.heatmap(corr,annot=True)
plt.show()

sse=[]
for i in range(1,11):
  km=KMeans(n_clusters=i)
  km.fit(df)
  sse.append(km.inertia_)

plt.plot(range(1,11),sse)
plt.show()

km=KMeans(n_clusters=2)
km.fit(df)
pred=km.predict(df)

print("Silhoutte score: ",silhouette_score(df,pred))

plt.scatter(df['Age'],df['Spending Score (1-100)'],c=pred)
plt.show()

plt.scatter(df['Annual Income (k$)'],df['Spending Score (1-100)'],c=pred)
plt.show()

"""Therfore the Model clearly seperates the the spending based on the Age and the Annual Income , using this data , the company can market more related items with gender and recommed,promote more budget-friendly items according to Annual Income

"""